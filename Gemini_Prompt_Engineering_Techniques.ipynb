{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Generative-AI-and-Prompt-Engineering/blob/main/Gemini_Prompt_Engineering_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rn1lLJXRfSZ"
      },
      "source": [
        "# Prompt Engineering Techniques\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --user --quiet google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"jrproject-402905\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "MODEL_ID = \"gemini-1.5-flash-preview-0514\"  # @param {type:\"string\"}\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lslYAvw37JGQ"
      },
      "outputs": [],
      "source": [
        "from vertexai.generative_models import GenerationConfig, GenerativeModel\n",
        "\n",
        "# load the model\n",
        "model = GenerativeModel(MODEL_ID, system_instruction=[ \"You are a helpful assistant.\",\"Your answer questions in a concise way\",],)\n",
        "\n",
        "# Set model parameters\n",
        "generation_config = GenerationConfig( temperature=0.9, top_k=32,)\n",
        "\n",
        "def generate_response(prompt,model=model):\n",
        "  contents = [prompt]\n",
        "  response = model.generate_content(contents, generation_config=generation_config,)\n",
        "  return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use Gemini 1.5 Flash model for these given below prompting techniques\n",
        "\n",
        "### There are different prompting techniques:\n",
        "**1) Multi-turn conversation or Chatbot with conversation history** <br>\n",
        "**2) Zero-shot Prompting** <br>\n",
        "**3) Few-shot Prompting** <br>\n",
        "**4) Chain-of-Thought Prompting** <br>\n",
        "**5) Tree-of-Thought Prompting** <br>\n",
        "**6) ReAct Prompting(Reason and Act)** <br>"
      ],
      "metadata": {
        "id": "26TpFzFpFPSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-turn Conversation**"
      ],
      "metadata": {
        "id": "X8VOeA5Ahta3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\n",
        "\n",
        "while True:\n",
        "  user = input(\"You: \")\n",
        "  if user == \"quit\":\n",
        "    break\n",
        "  prompt = prompt + \"User: \" + user + \"Assistant : \"\n",
        "  ans=generate_response(prompt)\n",
        "  print(\"Assistant: \", ans)\n",
        "  prompt = prompt + ans + \"\\n\"\n"
      ],
      "metadata": {
        "id": "7nzs8Zifhsr-",
        "outputId": "e55fff04-b352-4497-f3ab-0d34b754da36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hi\n",
            "Assistant:  Hi! üëã How can I help you today? \n",
            "\n",
            "You: i need help with learning AI?\n",
            "Assistant:  What specifically do you want to learn about AI?  \n",
            "* **Fundamentals?** (e.g., Machine Learning, Deep Learning)\n",
            "* **Specific AI techniques?** (e.g., Natural Language Processing, Computer Vision)\n",
            "* **Applications of AI?** (e.g., self-driving cars, chatbots) \n",
            "\n",
            "Let me know, and I'll guide you to the best resources! \n",
            "\n",
            "You: I want to begin with fundamentals\n",
            "Assistant:  Great! To start with AI fundamentals, I recommend focusing on **Machine Learning** and **Deep Learning**. \n",
            "\n",
            "Here are some excellent resources:\n",
            "\n",
            "* **Coursera:** Offers courses from top universities like Stanford and deeplearning.ai.\n",
            "* **edX:** Similar to Coursera, with courses from MIT, Harvard, and others.\n",
            "* **Fast.ai:** Provides a practical deep learning course for beginners.\n",
            "* **Andrew Ng's Machine Learning Course:** A classic course on Coursera, covering the basics of machine learning.\n",
            "\n",
            "Let me know if you have any specific areas you'd like to explore within fundamentals. I'm happy to help! \n",
            "\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero-shot prompting**\n",
        "\n",
        "Zero-shot prompting means that the prompt used to interact with the model won't contain examples or demonstrations. The zero-shot prompt directly instructs the model to perform a task without any additional examples to steer it."
      ],
      "metadata": {
        "id": "IV76I9qwIQeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt='''\n",
        "Message: Hi alex, thanks for the thoughtful birthday card!\n",
        "Sentiment: ?\n",
        "'''\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGtltyWkH5Hu",
        "outputId": "7068a789-fb0f-4bd7-ccae-1dd27e277483"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appreciation and gratitude. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Few-shot prompting**\n",
        "\n",
        "Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response."
      ],
      "metadata": {
        "id": "uJz9R8erKb3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Message: Hi Dad, you're 20 minutes late to my piano recital!\n",
        "Sentiment: Negative\n",
        "\n",
        "Message: Can't wait to order pizza for dinner tonight\n",
        "Sentiment: Positive\n",
        "\n",
        "Message: Hi Amit, thanks for the thoughtful birthday card!\n",
        "Sentiment: ?\n",
        "\"\"\"\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfn3Zh3HJnBQ",
        "outputId": "aa9fdc2d-b36c-4be7-ee43-cace207d0c7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specifying the Output Format\n",
        "- You can also specify the format in which you want the model to respond.\n",
        "- In the example below, you are asking to \"give a one word response\"."
      ],
      "metadata": {
        "id": "J3F2X283K2nG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Message: Hi Dad, you're 20 minutes late to my piano recital!\n",
        "Sentiment: Negative\n",
        "\n",
        "Message: Can't wait to order pizza for dinner tonight\n",
        "Sentiment: Positive\n",
        "\n",
        "Message: Hi Amit, thanks for the thoughtful birthday card!\n",
        "Sentiment: ?\n",
        "\n",
        "Give a one word response.\n",
        "\"\"\"\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E26iKMrKYK0",
        "outputId": "9b7d47c6-38cf-49f4-99e4-fc66c491a03a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chain-of-Thought Prompting**\n",
        "chain-of-thought (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. You can combine it with few-shot prompting to get better results on more complex tasks that require reasoning before responding."
      ],
      "metadata": {
        "id": "6z21K3uzVN8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
        "A: Adding all the odd numbers (17, 19) gives 36. The answer is True.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
        "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
        "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "A:\n",
        "\"\"\"\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPE0hYEUMGkX",
        "outputId": "b946376b-02ec-4df7-cec5-64f2ac88e1e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tree of Thoughts (ToT)**\n",
        "\n",
        "Tree of Thoughts (ToT) prompting is a framework that generalizes over chain-of-thought prompting and encourages exploration over thoughts that serve as intermediate steps for general problem-solving with language models.\n",
        "\n",
        "\n",
        "How does it work?\n",
        "\n",
        "- ToT prompting breaks problems down into smaller parts, similar to CoT prompting, but goes further by combining this with the ability to explore multiple solution paths in parallel, forming a tree instead of a single chain. Each thought is generated or solved independently and passed to the next step, allowing the model to self-evaluate and decide whether to continue with that path or choose another."
      ],
      "metadata": {
        "id": "bQvoNRxqVo5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = \"\"\"\n",
        "Imagine 5 different experts are answering this question.\n",
        "They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration\n",
        "All experts will write down 1 step of their thinking,\n",
        "then share it with the group.\n",
        "They will each critique their response, and the all the responses of others\n",
        "They will check their answer based on science and the laws of physics\n",
        "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts\n",
        "If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred\n",
        "If any expert realises they're wrong at any point then they acknowledges this and start another train of thought\n",
        "Each expert will assign a likelihood of their current assertion being correct\n",
        "Continue until the experts agree on the single most likely location\n",
        "The question is.\n",
        "1. Carlos is at the swimming pool.\n",
        "2. He walks to the locker room, carrying a towel.\n",
        "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
        "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
        "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
        "6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch?\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF7_WBM9MT78",
        "outputId": "464c31d5-8d16-4638-d2ec-d486952f6ce9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Expert Brainstorming:\n",
            "\n",
            "**Expert 1:**  The watch was last seen in the towel.  The towel was last seen at the snack bar.  **Therefore, the watch is most likely at the snack bar.** (Likelihood: 80%)\n",
            "\n",
            "**Expert 2:**  While the towel was at the snack bar, it was left unattended.  It's possible someone took the towel, or the watch fell out.  **We need to consider other locations.** (Likelihood: 60%)\n",
            "\n",
            "**Expert 3:** Carlos shook the towel vigorously before leaving it. **If the watch was loose, it would have likely fallen out during the shaking.** (Likelihood: 90%)\n",
            "\n",
            "**Expert 4:**  Carlos walked from the locker room to the poolside carrying the towel. **It's possible the watch fell out during this walk.** (Likelihood: 70%)\n",
            "\n",
            "**Expert 5:**  The watch was put in the towel in the locker room. **It's possible the watch fell out of the towel before Carlos left the locker room.** (Likelihood: 50%)\n",
            "\n",
            "**Discussion:**\n",
            "\n",
            "* **Expert 1's** assertion is challenged by **Expert 2's** point about the towel being unattended.\n",
            "* **Expert 3's** assertion that the watch would have fallen out during shaking is supported by the vigorous shaking.\n",
            "* **Expert 4's** suggestion that the watch could have fallen out on the walk to the poolside is less likely due to the towel being carried tightly.\n",
            "* **Expert 5's** suggestion that the watch could have fallen out in the locker room is the least likely, as Carlos was holding the towel tightly.\n",
            "\n",
            "**Revised Conclusion:**\n",
            "\n",
            "The most likely location of the watch is **at the snack bar** (Likelihood: 90%). It's highly probable the watch fell out during the vigorous shaking of the towel. While it's possible someone took the towel or the watch fell out at another location, the shaking of the towel makes it the most likely scenario. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ReAct Prompting**\n",
        "\n",
        "ReAct is a framework where LLMs are used to generate both reasoning traces and task-specific actions in an interleaved manner.\n",
        "\n",
        "Generating reasoning traces allow the model to induce, track, and update action plans, and even handle exceptions. The action step allows to interface with and gather information from external sources such as knowledge bases or environments."
      ],
      "metadata": {
        "id": "i3Sfro9fQ1sW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Solve a question answering task with interleaving\n",
        "Thought,\n",
        "Action,\n",
        "Observation steps.\n",
        "\n",
        "Thought can reason about the current situation, and Action can be three types:\n",
        "\n",
        "Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search.\n",
        "\n",
        "Calculator[query], it performs mathematical calculations based on input query.\n",
        "\n",
        "Lookup[keyword], which returns the next sentence containing keyword in the current passage.\n",
        "\n",
        "Finish[answer], which returns the answer and finishes the task.\n",
        "\n",
        "Question:\n",
        "\n",
        "Who is Elon Musk?\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u1q_MyZO68A",
        "outputId": "c607af79-8df2-477f-a2d9-d6d82712d92f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: I need to find information about Elon Musk.\n",
            "Action: Search[Elon Musk]\n",
            "Observation: Elon Reeve Musk (born June 28, 1971) is a business magnate and entrepreneur. \n",
            "Thought: I found the information I need.\n",
            "Action: Finish[Elon Reeve Musk (born June 28, 1971) is a business magnate and entrepreneur.] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Chain-of-Verification Prompting**\n",
        "\n",
        "The Chain-of-Verification (CoVe) prompt engineering method aims to reduce hallucinations through a verification loop."
      ],
      "metadata": {
        "id": "dPnsQc3hpQ7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Question=\"Name some athletes who were born in United states\"\n",
        "\n",
        "prompt=f'''Here is the question: {Question}.\n",
        "\n",
        "First, generate a response.\n",
        "\n",
        "Then, create and answer verification questions based on this response to check for accuracy. Think it through and make sure you are extremely accurate based on the question asked.\n",
        "\n",
        "After answering each verification question, consider these answers and revise the initial response to formulate a final, verified answer. Ensure the final response reflects the accuracy and findings from the verification process.'''\n",
        "\n",
        "\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9mjZtAJfDdm",
        "outputId": "02fd7f2f-0807-4f97-a922-150203852bcc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Initial Response:\n",
            "\n",
            "Some athletes born in the United States are Michael Jordan, Serena Williams, Tom Brady, and Tiger Woods.\n",
            "\n",
            "## Verification Questions:\n",
            "\n",
            "1. **Is Michael Jordan an American athlete?** - Yes\n",
            "2. **Is Serena Williams an American athlete?** - Yes\n",
            "3. **Is Tom Brady an American athlete?** - Yes\n",
            "4. **Is Tiger Woods an American athlete?** - Yes\n",
            "\n",
            "## Final Verified Response:\n",
            "\n",
            "The athletes Michael Jordan, Serena Williams, Tom Brady, and Tiger Woods were all born in the United States. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Step-Back Prompting**\n",
        "\n",
        "A crucial rule to remember when prompting LLMs is to give them space to 'think'. You don‚Äôt want to overly constrain the model such that it can‚Äôt explore various solutions.\n",
        "\n",
        "Chain of thought reasoning is one way to push the model to think through the problem. A simple way to implement this type of reasoning is to add a statement like ‚Äúthink through this task step-by-step‚Äù at the end of your prompt."
      ],
      "metadata": {
        "id": "YEF7Xk88tIQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Question=\"What is Quantum Physics?\"\n",
        "prompt=f'''Here is a question or task: {Question}\n",
        "\n",
        "Let's think step-by-step to answer this:\n",
        "\n",
        "Step 1) Abstract the key concepts and principles relevant to this question:\n",
        "\n",
        "Step 2) Use the abstractions to reason through the question:\n",
        "\n",
        "Final Answer: '''\n",
        "\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqmZDv7ApGI6",
        "outputId": "6879718a-a86e-4b2b-8966-95bf57af94e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Step 1: Key Concepts and Principles\n",
            "\n",
            "* **Quantum Mechanics:** A fundamental theory in physics that describes the physical properties of nature at the scale of atoms and subatomic particles.\n",
            "* **Quantization:** The idea that certain physical quantities, like energy, can only exist in discrete values, like steps on a ladder.\n",
            "* **Wave-particle duality:** The concept that particles like electrons can exhibit wave-like behavior and vice versa.\n",
            "* **Superposition:** The ability of a quantum system to exist in multiple states simultaneously until observed.\n",
            "* **Entanglement:** A phenomenon where two or more particles become linked, regardless of distance, and their fates are intertwined.\n",
            "\n",
            "## Step 2: Reasoning\n",
            "\n",
            "Quantum physics is the study of the behavior of matter and energy at the atomic and subatomic levels. Unlike classical physics, which describes the world at a larger scale, quantum physics introduces new concepts like quantization, wave-particle duality, superposition, and entanglement. These concepts lead to unique and counterintuitive phenomena, challenging our everyday understanding of the world.\n",
            "\n",
            "## Final Answer: \n",
            "\n",
            "Quantum physics is the study of the behavior of matter and energy at the atomic and subatomic levels, introducing concepts like quantization, wave-particle duality, superposition, and entanglement, which lead to unique and counterintuitive phenomena. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UfoRBs-os3rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thank You"
      ],
      "metadata": {
        "id": "23-8_wu6QI-j"
      }
    }
  ]
}