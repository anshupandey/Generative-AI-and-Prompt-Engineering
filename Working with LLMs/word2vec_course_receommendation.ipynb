{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Developing a word2vec model\n",
        "\n",
        "Objective:\n",
        "\n",
        "  To understand the process of training and using a word2vec model to capture semantic meaning from text data.\n",
        "\n",
        "Background:\n",
        "\n",
        "  Word2Vec is a popular method for representing words as vectors. The idea is to capture the semantic meaning of words based on their context in a given text corpus. This exercise will help students understand how to train a Word2Vec model and use it for various NLP tasks.\n",
        "\n",
        "Scenario:\n",
        "\n",
        "  Imagine you are working for an e-learning company, \"Blue Data EdTech\", which wants to recommend relevant courses to its users based on the content of courses they've previously enrolled in. You decide to use Word2Vec to understand the content of courses and then make relevant recommendations.\n",
        "\n",
        "Dataset:\n",
        "\n",
        "  The dataset consists of course descriptions from various subjects offered by \"Blue Data EdTech\". Each course description is about 100-200 words long, giving a brief overview of what the course covers.\n",
        "\n",
        "Data Cleaning and Pre-processing:\n",
        "- Load the dataset into a suitable data structure (e.g., pandas DataFrame).\n",
        "- Clean the data by removing any special characters, numbers, and converting all text to lowercase.\n",
        "- Tokenize the cleaned data.\n",
        "\n",
        "Train a Word2Vec Model:\n",
        "- Use the Gensim library to train a Word2Vec model on the tokenized course descriptions.\n",
        "- Experiment with different hyperparameters (e.g., vector size, window size, min_count) to optimize your model.\n",
        "\n",
        "Model Evaluation:\n",
        "- Use the model to find the most similar words to some test words (e.g., \"programming\", \"data\", \"design\").\n"
      ],
      "metadata": {
        "id": "JhUMrof_Sfs6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MnhrL2maSZzW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "df = pd.read_csv(\"Course_recommendation.csv\")\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E1t9nKTTWjB",
        "outputId": "974de88f-6a68-4a13-9859-0f5d25e0e181"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "tm4NxNpkTceL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corpus(ps):\n",
        "  text = ps['Domain'] + \" \" + ps[\"Course Title\"] + \" \" + ps['Course Description']\n",
        "  return text\n",
        "corpus = [get_corpus(df.iloc[s,:]) for s in range(df.shape[0])]\n",
        "corpus\n"
      ],
      "metadata": {
        "id": "jdBgI8enTeQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(doc):\n",
        "  doc = re.sub(\"[^a-zA-z0-9\\s]\",\"\",doc)\n",
        "  doc = doc.strip()\n",
        "  return doc\n",
        "\n",
        "corpus = [clean_data(doc) for doc in corpus]\n",
        "corpus"
      ],
      "metadata": {
        "id": "miTG3KM1UMY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [doc.lower().split() for doc in corpus]\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "sw =list(ENGLISH_STOP_WORDS)\n",
        "\n",
        "corpus = [[w for w in doc if w not in sw] for doc in corpus]"
      ],
      "metadata": {
        "id": "KU5DH-8SWX6I"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Developing a word2vec model using gensim"
      ],
      "metadata": {
        "id": "yDlhk7EeVV99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models"
      ],
      "metadata": {
        "id": "zsh7X22kUzxy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Word2Vec(corpus,vector_size=10,window=3,min_count=1,epochs=20)"
      ],
      "metadata": {
        "id": "BAFaObPSVpe5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xixBWQLWQXx",
        "outputId": "37a71e35-c35b-4ed7-ce6d-26b8da1d368f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x7f9e300cb8b0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv['python']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfTjR3rKWnSa",
        "outputId": "ea953258-5533-4967-b8d1-9c70ff951443"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.06664161, -0.09053505, -0.03858478,  0.00308311, -0.09070887,\n",
              "       -0.01679079,  0.06406178,  0.06560419, -0.03008008, -0.0251871 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"design\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9faV3uMPWqKr",
        "outputId": "44f4ba88-3a0b-43ef-b136-f5b1ff9b5e70"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('photoshop', 0.867955207824707),\n",
              " ('neural', 0.8625140190124512),\n",
              " ('data', 0.8281702995300293),\n",
              " ('art', 0.8266161680221558),\n",
              " ('cloud', 0.7981105446815491),\n",
              " ('covers', 0.7965190410614014),\n",
              " ('spark', 0.7853581309318542),\n",
              " ('funding', 0.7693154811859131),\n",
              " ('variables', 0.7692983150482178),\n",
              " ('learn', 0.7668612003326416)]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"programming\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhALZ7r8WyC9",
        "outputId": "9f4492dc-1147-42bf-c2fd-8cf129063217"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('started', 0.9157686233520508),\n",
              " ('protect', 0.8068074584007263),\n",
              " ('seo', 0.805827260017395),\n",
              " ('techniques', 0.7980539202690125),\n",
              " ('power', 0.7945994138717651),\n",
              " ('concepts', 0.7859807014465332),\n",
              " ('optimization', 0.78365159034729),\n",
              " ('resource', 0.7811184525489807),\n",
              " ('include', 0.7451245784759521),\n",
              " ('world', 0.7399213910102844)]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZNGGiajX_aV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}