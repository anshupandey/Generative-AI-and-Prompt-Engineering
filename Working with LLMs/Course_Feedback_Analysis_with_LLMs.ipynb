{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "  Case Study: Analyzing Student Feedback using LLMs\n",
        "\n",
        "  Background:\n",
        "\n",
        "  In the edtech space, it's common for platforms to receive vast amounts of feedback from students. This feedback can be about course content, platform usability, instructor quality, etc. Analyzing this feedback manually can be time-consuming. LLMs can assist in summarizing and categorizing this feedback for actionable insights.\n",
        "\n",
        "  Problem Statement:\n",
        "\n",
        "  MTT Consuling & Edtech wants to analyze feedback from students to improve their online course offerings. The feedback is in the form of text, and there are thousands of responses. The goal is to categorize feedback into themes (e.g., \"Course Content\", \"Instructor Quality\", \"Platform Usability\") and understand common sentiments (positive, negative, neutral).\n",
        "\n",
        "  Challenges:\n",
        "\n",
        "  •\tLarge volume of feedback.\n",
        "  •\tVariability in language and expression among students.\n",
        "  •\tNeed for accurate categorization and sentiment analysis.\n",
        "\n",
        "  Dataset:\n",
        "\n",
        "  For this case study, we'll use the \"Online Course Reviews\" dataset from Kaggle. This dataset contains textual feedback from various online courses.\n",
        "\n",
        "```\n",
        "\n",
        "  Data Pre-processing:\n",
        "\n",
        "  •\tLoad the dataset and perform basic cleaning (remove duplicates, handle missing values).\n",
        "  •\tTokenize the feedback using LLM-specific tokenizers.\n",
        "\n",
        "  Categorization with LLM:\n",
        "  •\tFine-tune an LLM (like BERT) on a subset of manually labeled feedback to classify into categories.\n",
        "  •\tUse the fine-tuned model to predict categories for the entire dataset.\n",
        "\n",
        "  Sentiment Analysis:\n",
        "  •\tUse a pre-trained sentiment analysis model (like the ones available in HuggingFace's transformers library) to determine the sentiment of each feedback.\n",
        "\n",
        "  Results Visualization:\n",
        "  •\tVisualize the distribution of feedback across categories.\n",
        "  •\tVisualize sentiment distribution within each category.\n",
        "\n",
        "\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "VD5Lvn3zV6p4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6_qz078Vtu2",
        "outputId": "57cfd133-acc5-48f9-b1fc-bf8d6a3c8978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rjUir47gC1c",
        "outputId": "7a61fbf2-9ded-40f7-aaec-78ee9f9ebe03"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/258.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/258.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip reviews.csv.zip"
      ],
      "metadata": {
        "id": "KIxqiApJWNka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration, Cleaning and Preparation"
      ],
      "metadata": {
        "id": "hm7MGPE4WYND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "760pMPIvWVEa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('review1100_categorized.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wziYSNx-WkTM",
        "outputId": "e4cb82b1-6a7c-4e3d-b8a8-2ae78ca9bbcd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1147, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicate entries\n",
        "print(df.shape)\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw6-uf_BWr2g",
        "outputId": "f19e45f2-6d13-4c21-c334-349c2f8f682c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1147, 4)\n",
            "(1147, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5mljjHTXSeI",
        "outputId": "ce320261-7e32-4690-e35a-850268768823"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id          0\n",
              "Review      0\n",
              "Label       0\n",
              "Category    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in np.random.randint(1,df.shape[0],10):\n",
        "  print(df['Review'][i])\n",
        "  print(\"#\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rX0fMMCXWlH",
        "outputId": "bdaff54b-0b73-465e-bc76-14478cf42eb9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It's really well organized. I like the pace of the course and the voice of \"Professor Andy\"!\n",
            "##################################################\n",
            "I am in love for this course, a lot of good information, practice activities, etc...It is helping me a lot!\n",
            "##################################################\n",
            "Awesome course, excelent material, great classes.\n",
            "##################################################\n",
            "Some great material and I learned a lot. I did in fact complete the course but chose not to submit written material. Sometimes the lecturer was perhaps a little dry.\n",
            "##################################################\n",
            "It's a very nice course if you're doing some refreshing of college chemistry.\n",
            "##################################################\n",
            "Suberb introducition into 3d printing idea and usage\n",
            "##################################################\n",
            "Definitely recommend this short course which gives a good overview of Ableton Live's capabilities and how to use them.\n",
            "##################################################\n",
            "Thank you very much for this awesome course, I really enjoyed and learned alot from it.I really liked the selected topics, they act like an intro to some really interesting fields in the programming.I've learned about NP multiple times but never found a use to it until now, the problems were really good and informative.I think the linear programming was pretty rushed, it should've been expanded over two weeks with more in details.Maybe add a problem or explain the use of duality .\n",
            "##################################################\n",
            "I thought this was a great high-level intro to the world of 3D printing.\n",
            "##################################################\n",
            "I will keep thinking with the Greeks.\n",
            "##################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(doc):\n",
        "  doc = re.sub(\":[a-zA-Z0-9().-]+\",\"\",doc)\n",
        "  doc = re.sub(\"[^a-zA-Z0-9\\s]\",\"\",doc)\n",
        "  doc = re.sub(\"\\s\\s\",\" \",doc)\n",
        "  doc = doc.strip()\n",
        "  return doc\n",
        "\n",
        "clean_data(\"my name is Anshu :D and :) what is 'your' name ???---...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ak9aqkuUXcgE",
        "outputId": "ebd57863-f90c-49d4-a9bf-839b74381274"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'my name is Anshu and what is your name'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Review'] = df['Review'].apply(clean_data)"
      ],
      "metadata": {
        "id": "PvdRL7CYYfOk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in np.random.randint(1,df.shape[0],10):\n",
        "  print(df['Review'][i])\n",
        "  print(\"#\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT9azWdHYzh3",
        "outputId": "88062361-5951-40a7-c131-4989e0c5fed6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I greatly enjoyed the material presented in this course and while I do not doubt the proficiency of its creators the poor standard of spoken English of its two main presenters prevents me from recommending it to colleagues As another reviewer has remarked their English may be quite sufficient for day to day use with other experts but for inadequate for teaching students who are hearing many technical terms for the first time The transcripts are no better and also contain many mistakes I believe that this course should be stopped until these problems are corrected\n",
            "##################################################\n",
            "Great course A must for every individual who has some idea about it and even if you dont Aric and his team will guide you throughout this wonderful technique\n",
            "##################################################\n",
            "Worldclass\n",
            "##################################################\n",
            "Great intro to Ableton with good handson experience Nice starting point for those who seek to expand their music creation toolset\n",
            "##################################################\n",
            "Great course and teachers\n",
            "##################################################\n",
            "Dont recommendYoure better off skimming through the ableton manual and using the search function to get the answers you want\n",
            "##################################################\n",
            "This course has relatively few instructions about homework I believe more test cases would be betterThough able to be found in forum Besides lecture is really awesome Thanks a lot\n",
            "##################################################\n",
            "Content very clear and explained by the professors\n",
            "##################################################\n",
            "Great Introduction into the programa quick look I felt the tutorial in the program covered a lot and most of the info here can be found on youtube Although you dont get a certificate for watching youtube\n",
            "##################################################\n",
            "Excellent It is a representation of our day by day thanks for sharing your vision experience and advicesRegardsDaniel Damas\n",
            "##################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "geEa3C57ajWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "input_data = tokenizer(list(df['Review']),truncation=True,padding=True,max_length=512)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "O6Dgh6hKY052"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Category']\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "4bXhqqgekgKJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --quiet"
      ],
      "metadata": {
        "id": "aeu4QCxwlRY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "train_data = Dataset.from_dict({'input_ids':input_data['input_ids'],'labels':y})"
      ],
      "metadata": {
        "id": "jUU1GvMpk02S"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification Model"
      ],
      "metadata": {
        "id": "Qp44pkDUeNzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "mdoel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sotv9BPwb12j",
        "outputId": "82c0cce5-fdbb-49ac-8d58-e79e1e8655f6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    logging_dir='./logs'\n",
        ")\n",
        "\n",
        "# create a trianer object to train a model\n",
        "trainer = Trainer(model=mdoel,\n",
        "                  args = training_args,\n",
        "                  train_dataset=train_data)\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "PtmGqyNFevoc",
        "outputId": "be00e2ec-599a-4277-a33a-d4d3adabe9c2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='720' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [720/720 09:47, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.316000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=720, training_loss=0.31351425382826065, metrics={'train_runtime': 592.3106, 'train_samples_per_second': 9.682, 'train_steps_per_second': 1.216, 'total_flos': 1508955450670080.0, 'train_loss': 0.31351425382826065, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = le.classes_.tolist()\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtxo04t8htdo",
        "outputId": "7d76d540-a6a4-408f-d5d0-a5a633074e41"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Course Content', 'Instructor Quality', 'Platform Usability']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = []\n",
        "actuals = []\n",
        "for i in np.random.randint(0,df.shape[0],5):\n",
        "  testset.append(df['Review'][i])\n",
        "  actuals.append(df['Category'][i])"
      ],
      "metadata": {
        "id": "gqL3mjptihBI"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset"
      ],
      "metadata": {
        "id": "oJbrRA9TpIOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = Dataset.from_dict({\"input_ids\":tokenizer(testset,truncation=True,padding=True,max_length=512)['input_ids']})\n",
        "preds = trainer.predict(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "yCWgLzWOpM5G",
        "outputId": "de708b0a-8d67-483d-aa0a-ad6aacb3943e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "AvpByTQ1p_gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(testset[i])\n",
        "  p = np.argmax(preds[0][i])\n",
        "  print(actuals[i],class_names[p])"
      ],
      "metadata": {
        "id": "_2xOUzP4phG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sanmQm2GqFSW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}