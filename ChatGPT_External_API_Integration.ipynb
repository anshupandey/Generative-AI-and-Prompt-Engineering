{
<<<<<<< HEAD
=======
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Generative-AI-and-Prompt-Engineering/blob/main/ChatGPT_External_API_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KQD1SXcnSYu",
        "outputId": "6d077b44-7f71-4229-c03f-283c6a5eab70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai --quiet\n",
        "!pip install ipython --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In an API call, you can describe functions and have the model intelligently choose to output a JSON object containing arguments to call one or many functions. The Chat Completions API does not call the function; instead, the model generates JSON that you can use to call the function in your code."
      ],
      "metadata": {
        "id": "CMs1SliPer2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supported models\n",
        "Not all model versions are trained with function calling data. Function calling is supported with the following models: gpt-4, gpt-4-turbo-preview, gpt-4-0125-preview, gpt-4-1106-preview, gpt-4-0613, gpt-3.5-turbo, gpt-3.5-turbo-0125, gpt-3.5-turbo-1106, and gpt-3.5-turbo-0613\n",
        "\n",
        "In addition, parallel function calls is supported on the following models: gpt-4-turbo-preview, gpt-4-0125-preview, gpt-4-1106-preview, gpt-3.5-turbo-0125, and gpt-3.5-turbo-1106"
      ],
      "metadata": {
        "id": "O6voT6dEZOEQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP21QdTRno_A"
      },
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "key = \"sk-kQRxxxxxxxxxxxxxxxxxxxxxxxxxc8Xhl0xj2ezY\"\n",
        "import openai\n",
        "import json\n",
        "import requests\n",
        "openai.api_key = key"
      ]
=======
        "import os\n",
        "import requests\n",
        "import json\n",
        "from openai import OpenAI\n",
        "os.environ['OPENAI_API_KEY'] = \"sk-xxxxxxxxxxxxxxxxxxx\"\n",
        "\n",
        "# Initializing a client object: gets the API Key from environment variable OPENAI_API_KEY\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "qP21QdTRno_A"
      },
      "execution_count": 8,
      "outputs": []
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAoRt2AvoCJ_"
      },
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# create a dummy function to respond temperature\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "  \"This function can be used to fetch the current weather information when provided with details such as location and unit for temperature\"\n",
        "  weather_info = {\n",
        "      \"location\":location,\n",
        "      \"temperature\":\"125\",\n",
        "      \"unit\":unit,\n",
        "      \"forecast\":['sunny','windy']\n",
        "  }\n",
        "  return json.dumps(weather_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUAVQTH1FCob"
      },
      "outputs": [],
      "source": [
        "owm_api = \"714fc19dbcb1741906cf9c832b1fa4af\"\n",
=======
        "owm_api = \"xxxxxxxxxxx\"\n",
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
        "\n",
        "# create a dummy function to respond temperature\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "  \"This function can be used to fetch the current weather information when provided with details such as location and unit for temperature\"\n",
        "\n",
        "  url = f\"https://api.openweathermap.org/data/2.5/weather?q={location}&appid={owm_api}\"\n",
        "  response = requests.get(url)\n",
        "  temp = response.json()['main']['temp']\n",
        "  forecast = [response.json()['weather'][0]['main'],response.json()['weather'][0]['description']]\n",
        "\n",
        "  weather_info = {\n",
        "      \"location\":location,\n",
        "      \"temperature\":temp,\n",
        "      \"unit\":'Kelvin',\n",
        "      \"forecast\":forecast\n",
        "  }\n",
        "  return json.dumps(weather_info)"
<<<<<<< HEAD
      ]
=======
      ],
      "metadata": {
        "id": "FUAVQTH1FCob"
      },
      "execution_count": 9,
      "outputs": []
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zvpewsATGB30",
        "outputId": "0cbfc1a7-6f12-47a0-aa71-019ed866cdcc"
      },
<<<<<<< HEAD
=======
      "execution_count": 10,
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
      "outputs": [
        {
          "data": {
<<<<<<< HEAD
=======
            "text/plain": [
              "'{\"location\": \"Mumbai\", \"temperature\": 296.14, \"unit\": \"Kelvin\", \"forecast\": [\"Smoke\", \"smoke\"]}'"
            ],
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"location\": \"Mumbai\", \"temperature\": 300.14, \"unit\": \"Kelvin\", \"forecast\": [\"Mist\", \"mist\"]}'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
<<<<<<< HEAD
          "output_type": "execute_result"
=======
          "execution_count": 10
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
        }
      ],
      "source": [
        "get_current_weather(\"Mumbai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSSkDmeiokTL"
      },
      "outputs": [],
      "source": [
        "tools = [{\n",
        "                            \"type\":\"function\",\n",
        "                            \"function\":{\"name\": \"get_current_weather\",\n",
        "                           \"description\": \"This function can be used to fetch the current weather information when provided with details such as location and unit for temperature\",\n",
        "                           \"parameters\": {\n",
        "                               \"type\": \"object\",\n",
        "                               \"properties\": {\"location\": {\n",
        "                                   \"type\": \"string\",\n",
        "                                   \"description\": \"The name of city/state/country for which weather information is to be fetched\",},},\n",
        "                               \"required\": [\"location\",],},},}]\n",
        "\n",
        "\n",
        "\n",
        "def get_response(messages, tools,model=\"gpt-3.5-turbo-1106\"):\n",
        "  response = client.chat.completions.create(model = model, messages = messages, tools=tools, tool_choice='auto', temperature=0.5,)\n",
        "  response = response.choices[0].message\n",
        "  tool_calls = response.tool_calls\n",
        "\n",
        "  try:\n",
        "    if tool_calls:\n",
        "      print(\"Making a function call\")\n",
        "      # get available functions\n",
        "      available_functions = {\n",
        "          \"get_current_weather\":get_current_weather,\n",
        "      }\n",
        "\n",
        "      # get details to call the function assuming there is only one function call\n",
        "      func_name = tool_calls[0].function.name\n",
        "      func_to_call = available_functions[func_name]\n",
        "      func_args = json.loads(tool_calls[0].function.arguments)\n",
        "\n",
        "      # call the external api by calling the function\n",
        "      func_response = func_to_call(**func_args)\n",
        "\n",
        "      # again make a call to openai api to communicate results from external function/API\n",
        "      messages.append(response)\n",
        "      messages.append(\n",
        "          {\"tool_call_id\":tool_calls[0].id,\n",
        "          \"role\":\"tool\",\n",
        "          \"name\":func_name,\n",
        "          \"content\":str(func_response)}\n",
        "      )\n",
        "\n",
        "      second_response = client.chat.completions.create(\n",
        "      model = \"gpt-3.5-turbo-1106\",\n",
        "      messages = messages)\n",
        "      return second_response\n",
        "    else:\n",
        "      return response.content\n",
        "  except Exception as e:\n",
        "      print(\"Error occurred \",e)\n",
<<<<<<< HEAD
        "  return response_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
=======
        "      return response\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9gdvGUJGbheA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"Provide a 2 line explanation for AI\"}]\n",
        "response = get_response(messages, tools)\n",
        "print(response)"
      ],
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
      "metadata": {
        "id": "FWL0wVqFdeBm",
        "outputId": "4ec4827f-6563-4d21-c1f2-7a1d6969ee41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
<<<<<<< HEAD
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-80fvr2UAnaLTJqwrs1Bh59tLTWBJN at 0x7c5a43746ca0> JSON: {\n",
              "  \"id\": \"chatcmpl-80fvr2UAnaLTJqwrs1Bh59tLTWBJN\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1695171879,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"The current weather in Berlin is clear with a temperature of 288.58 Kelvin.\"\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 71,\n",
              "    \"completion_tokens\": 17,\n",
              "    \"total_tokens\": 88\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
=======
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI, or Artificial Intelligence, is a branch of computer science that aims to create intelligent machines capable of simulating human cognitive processes. It involves the development of algorithms and systems that can perceive, reason, learn, and act in a way that mimics human intelligence.\n"
          ]
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
        }
      ],
      "source": [
        "chatbot(\"What is the weather in Berlin today?\")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": null,
=======
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"How is the weather in Mumbai today?\"}]\n",
        "response = get_response(messages, tools)\n",
        "print(response.choices[0].message.content)"
      ],
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
      "metadata": {
        "id": "h0H4DaivdmPW",
        "outputId": "1ed3dbe2-8da1-427e-c81a-ac3cf2dae0e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
<<<<<<< HEAD
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x7c5a43785d50> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": \"Sure, here's a joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\"\n",
              "}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
=======
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making a function call\n",
            "The weather in Mumbai today is smoky with a temperature of 297.14 Kelvin.\n"
          ]
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
        }
      ],
      "source": [
        "chatbot(\"Tell me a joke\")"
      ]
<<<<<<< HEAD
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTb_CD6br8Qx",
        "outputId": "076d0fbc-941b-4dde-b490-a3e3c820475b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-80fwATG1WD7LgHmj8uY9fiZ922fYa at 0x7c5a437015d0> JSON: {\n",
              "  \"id\": \"chatcmpl-80fwATG1WD7LgHmj8uY9fiZ922fYa\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1695171898,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"The weather in Manila today is partly cloudy with scattered clouds. The temperature is approximately 303.49 Kelvin.\"\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 75,\n",
              "    \"completion_tokens\": 22,\n",
              "    \"total_tokens\": 97\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chatbot(\"What is the weather in Manila today?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp6RiF-Eud6X"
      },
      "outputs": [],
      "source": []
=======
>>>>>>> 3df47b6d5384df61612e6e0a477b3b0e143daf84
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
