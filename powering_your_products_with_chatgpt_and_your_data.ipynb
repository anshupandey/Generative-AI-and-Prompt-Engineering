{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Generative-AI-and-Prompt-Engineering/blob/main/powering_your_products_with_chatgpt_and_your_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63785634",
      "metadata": {
        "id": "63785634"
      },
      "source": [
        "# Power your products with ChatGPT and your own data\n",
        "\n",
        "This is a walkthrough taking readers through how to build starter Q&A and Chatbot applications using the ChatGPT API and their own data.\n",
        "\n",
        "It is laid out in these sections:\n",
        "- **Setup:**\n",
        "    - Initiate variables and source the data\n",
        "- **Lay the foundations:**\n",
        "    - Set up the vector database to accept vectors and data\n",
        "    - Load the dataset, chunk the data up for embedding and store in the vector database\n",
        "- **Make it a product:**\n",
        "    - Add a retrieval step where users provide queries and we return the most relevant entries\n",
        "    - Summarise search results with GPT-3\n",
        "    - Test out this basic Q&A app in Streamlit\n",
        "- **Build your moat:**\n",
        "    - Create an Assistant class to manage context and interact with our bot\n",
        "    - Use the Chatbot to answer questions using semantic search context\n",
        "    - Test out this basic Chatbot app in Streamlit\n",
        "    \n",
        "Upon completion, you have the building blocks to create your own production chatbot or Q&A application using OpenAI APIs and a vector database.\n",
        "\n",
        "This notebook was originally presented with [these slides](https://drive.google.com/file/d/1dB-RQhZC_Q1iAsHkNNdkqtxxXqYODFYy/view?usp=share_link), which provide visual context for this journey."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "59f08ea7",
      "metadata": {
        "id": "59f08ea7"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13649895",
      "metadata": {
        "id": "13649895"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First we'll setup our libraries and environment variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai --quiet\n",
        "!pip install tiktoken --quiet\n",
        "!pip install textract --quiet\n"
      ],
      "metadata": {
        "id": "LYgZchbksfWo"
      },
      "id": "LYgZchbksfWo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
        "EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n",
        "CHAT_MODEL = 'gpt-3.5-turbo'\n",
        "TEXT_EMBEDDING_CHUNK_SIZE=300\n",
        "VECTOR_FIELD_NAME='content_vector'\n",
        "PREFIX = \"sportsdoc\"\n",
        "INDEX_NAME = \"f1-index\""
      ],
      "metadata": {
        "id": "OCqxNI56s64J"
      },
      "id": "OCqxNI56s64J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile database.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openai\n",
        "from redis import Redis\n",
        "from redis.commands.search.field import VectorField\n",
        "from redis.commands.search.field import TextField, NumericField\n",
        "from redis.commands.search.query import Query\n",
        "\n",
        "from config import EMBEDDINGS_MODEL, PREFIX, VECTOR_FIELD_NAME\n",
        "\n",
        "# Get a Redis connection\n",
        "def get_redis_connection(host='localhost',port='6379',db=0):\n",
        "\n",
        "    r = Redis(host=host, port=port, db=db,decode_responses=False)\n",
        "    return r\n",
        "\n",
        "# Create a Redis index to hold our data\n",
        "def create_hnsw_index (redis_conn,vector_field_name,vector_dimensions=1536, distance_metric='COSINE'):\n",
        "    redis_conn.ft().create_index([\n",
        "        VectorField(vector_field_name, \"HNSW\", {\"TYPE\": \"FLOAT32\", \"DIM\": vector_dimensions, \"DISTANCE_METRIC\": distance_metric}),\n",
        "        TextField(\"filename\"),\n",
        "        TextField(\"text_chunk\"),\n",
        "        NumericField(\"file_chunk_index\")\n",
        "    ])\n",
        "\n",
        "# Create a Redis pipeline to load all the vectors and their metadata\n",
        "def load_vectors(client:Redis, input_list, vector_field_name):\n",
        "    p = client.pipeline(transaction=False)\n",
        "    for text in input_list:\n",
        "        #hash key\n",
        "        key=f\"{PREFIX}:{text['id']}\"\n",
        "\n",
        "        #hash values\n",
        "        item_metadata = text['metadata']\n",
        "        #\n",
        "        item_keywords_vector = np.array(text['vector'],dtype= 'float32').tobytes()\n",
        "        item_metadata[vector_field_name]=item_keywords_vector\n",
        "\n",
        "        # HSET\n",
        "        p.hset(key,mapping=item_metadata)\n",
        "\n",
        "    p.execute()\n",
        "\n",
        "# Make query to Redis\n",
        "def query_redis(redis_conn,query,index_name, top_k=2):\n",
        "\n",
        "\n",
        "\n",
        "    ## Creates embedding vector from user query\n",
        "    embedded_query = np.array(openai.Embedding.create(\n",
        "                                                input=query,\n",
        "                                                model=EMBEDDINGS_MODEL,\n",
        "                                            )[\"data\"][0]['embedding'], dtype=np.float32).tobytes()\n",
        "\n",
        "    #prepare the query\n",
        "    q = Query(f'*=>[KNN {top_k} @{VECTOR_FIELD_NAME} $vec_param AS vector_score]').sort_by('vector_score').paging(0,top_k).return_fields('vector_score','filename','text_chunk','text_chunk_index').dialect(2)\n",
        "    params_dict = {\"vec_param\": embedded_query}\n",
        "\n",
        "\n",
        "    #Execute the query\n",
        "    results = redis_conn.ft(index_name).search(q, query_params = params_dict)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Get mapped documents from Weaviate results\n",
        "def get_redis_results(redis_conn,query,index_name):\n",
        "\n",
        "    # Get most relevant documents from Redis\n",
        "    query_result = query_redis(redis_conn,query,index_name)\n",
        "\n",
        "    # Extract info into a list\n",
        "    query_result_list = []\n",
        "    for i, result in enumerate(query_result.docs):\n",
        "        result_order = i\n",
        "        text = result.text_chunk\n",
        "        score = result.vector_score\n",
        "        query_result_list.append((result_order,text,score))\n",
        "\n",
        "    # Display result as a DataFrame for ease of us\n",
        "    result_df = pd.DataFrame(query_result_list)\n",
        "    result_df.columns = ['id','result','certainty']\n",
        "    return result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SYfAwAks-iX",
        "outputId": "245816a7-fa8d-44c6-ba78-62fa53d252ca"
      },
      "id": "9SYfAwAks-iX",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing database.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install redis --quiet"
      ],
      "metadata": {
        "id": "FslnRJGJtZUX",
        "outputId": "e01ca9da-e155-4168-cbb3-4d043b164350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FslnRJGJtZUX",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/250.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/250.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.1/250.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7590fbfc",
      "metadata": {
        "id": "7590fbfc"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Iterator\n",
        "import tiktoken\n",
        "import textract\n",
        "from numpy import array, average\n",
        "\n",
        "from database import get_redis_connection\n",
        "\n",
        "# Set our default models and chunking size\n",
        "from config import COMPLETIONS_MODEL, EMBEDDINGS_MODEL, CHAT_MODEL, TEXT_EMBEDDING_CHUNK_SIZE, VECTOR_FIELD_NAME\n",
        "\n",
        "# Ignore unclosed SSL socket warnings - optional in case you get these errors\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"unclosed\", category=ImportWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "760efc1e",
      "metadata": {
        "id": "760efc1e"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "i-mskezUu8JY",
        "outputId": "31880123-9fd1-4721-f375-0146e9f27d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "i-mskezUu8JY",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: FIA Practice Directions - Competitor's Staff Registration System.pdf  \n",
            "  inflating: fia_2022_formula_1_sporting_regulations_-_issue_9_-_2022-10-19_0.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3f90817d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f90817d",
        "outputId": "de21bb48-f015-4562-c118-a81bdffb1b9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"FIA Practice Directions - Competitor's Staff Registration System.pdf\",\n",
              " 'fia_2022_formula_1_sporting_regulations_-_issue_9_-_2022-10-19_0.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data_dir = os.path.join(os.curdir,'/content/')\n",
        "pdf_files = sorted([x for x in os.listdir(data_dir) if '.pdf' in x])\n",
        "pdf_files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc4018c",
      "metadata": {
        "id": "5dc4018c"
      },
      "source": [
        "## Laying the foundations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "632b82ed",
      "metadata": {
        "id": "632b82ed"
      },
      "source": [
        "### Storage\n",
        "\n",
        "We're going to use Redis as our database for both document contents and the vector embeddings. You will need the full Redis Stack to enable use of Redisearch, which is the module that allows semantic search - more detail is in the [docs for Redis Stack](https://redis.io/docs/stack/get-started/install/docker/).\n",
        "\n",
        "To set this up locally, you will need to install Docker and then run the following command: ```docker run -d --name redis-stack -p 6379:6379 -p 8001:8001 redis/redis-stack:latest```.\n",
        "\n",
        "The code used here draws heavily on [this repo](https://github.com/RedisAI/vecsim-demo).\n",
        "\n",
        "After setting up the Docker instance of Redis Stack, you can follow the below instructions to initiate a Redis connection and create a Hierarchical Navigable Small World (HNSW) index for semantic search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "17d6b886",
      "metadata": {
        "id": "17d6b886"
      },
      "outputs": [],
      "source": [
        "# Setup Redis\n",
        "from redis import Redis\n",
        "from redis.commands.search.query import Query\n",
        "from redis.commands.search.field import (\n",
        "    TextField,\n",
        "    VectorField,\n",
        "    NumericField\n",
        ")\n",
        "from redis.commands.search.indexDefinition import (\n",
        "    IndexDefinition,\n",
        "    IndexType\n",
        ")\n",
        "\n",
        "redis_client = get_redis_connection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4f3d3e6b",
      "metadata": {
        "id": "4f3d3e6b"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "VECTOR_DIM = 1536 #len(data['title_vector'][0]) # length of the vectors\n",
        "#VECTOR_NUMBER = len(data)                 # initial number of vectors\n",
        "PREFIX = \"sportsdoc\"                            # prefix for the document keys\n",
        "DISTANCE_METRIC = \"COSINE\"                # distance metric for the vectors (ex. COSINE, IP, L2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d3c352ca",
      "metadata": {
        "id": "d3c352ca"
      },
      "outputs": [],
      "source": [
        "# Create search index\n",
        "\n",
        "# Index\n",
        "INDEX_NAME = \"f1-index\"           # name of the search index\n",
        "VECTOR_FIELD_NAME = 'content_vector'\n",
        "\n",
        "# Define RediSearch fields for each of the columns in the dataset\n",
        "# This is where you should add any additional metadata you want to capture\n",
        "filename = TextField(\"filename\")\n",
        "text_chunk = TextField(\"text_chunk\")\n",
        "file_chunk_index = NumericField(\"file_chunk_index\")\n",
        "\n",
        "# define RediSearch vector fields to use HNSW index\n",
        "\n",
        "text_embedding = VectorField(VECTOR_FIELD_NAME,\n",
        "    \"HNSW\", {\n",
        "        \"TYPE\": \"FLOAT32\",\n",
        "        \"DIM\": VECTOR_DIM,\n",
        "        \"DISTANCE_METRIC\": DISTANCE_METRIC\n",
        "    }\n",
        ")\n",
        "# Add all our field objects to a list to be created as an index\n",
        "fields = [filename,text_chunk,file_chunk_index,text_embedding]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6c78b7e",
      "metadata": {
        "id": "a6c78b7e"
      },
      "outputs": [],
      "source": [
        "redis_client.ping()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3ad41f",
      "metadata": {
        "id": "cf3ad41f",
        "outputId": "b2d989db-e7ff-4a14-ef77-94a8a66bc173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not there yet. Creating\n"
          ]
        }
      ],
      "source": [
        "# Optional step to drop the index if it already exists\n",
        "#redis_client.ft(INDEX_NAME).dropindex()\n",
        "\n",
        "# Check if index exists\n",
        "try:\n",
        "    redis_client.ft(INDEX_NAME).info()\n",
        "    print(\"Index already exists\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    # Create RediSearch Index\n",
        "    print('Not there yet. Creating')\n",
        "    redis_client.ft(INDEX_NAME).create_index(\n",
        "        fields = fields,\n",
        "        definition = IndexDefinition(prefix=[PREFIX], index_type=IndexType.HASH)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f74ebeb5",
      "metadata": {
        "id": "f74ebeb5"
      },
      "source": [
        "### Ingestion\n",
        "\n",
        "We'll load up our PDFs and do the following\n",
        "- Initiate our tokenizer\n",
        "- Run a processing pipeline to:\n",
        "    - Mine the text from each PDF\n",
        "    - Split them into chunks and embed them\n",
        "    - Store them in Redis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile transformers2.py\n",
        "from typing import Iterator\n",
        "from numpy import array, average\n",
        "import openai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from config import TEXT_EMBEDDING_CHUNK_SIZE, EMBEDDINGS_MODEL\n",
        "from database import load_vectors\n",
        "\n",
        "def get_col_average_from_list_of_lists(list_of_lists):\n",
        "    \"\"\"Return the average of each column in a list of lists.\"\"\"\n",
        "    if len(list_of_lists) == 1:\n",
        "        return list_of_lists[0]\n",
        "    else:\n",
        "        list_of_lists_array = array(list_of_lists)\n",
        "        average_embedding = average(list_of_lists_array, axis=0)\n",
        "        return average_embedding.tolist()\n",
        "\n",
        "# Create embeddings for a text using a tokenizer and an OpenAI engine\n",
        "\n",
        "\n",
        "def create_embeddings_for_text(text, tokenizer):\n",
        "    \"\"\"Return a list of tuples (text_chunk, embedding) and an average embedding for a text.\"\"\"\n",
        "    token_chunks = list(chunks(text, TEXT_EMBEDDING_CHUNK_SIZE, tokenizer))\n",
        "    text_chunks = [tokenizer.decode(chunk) for chunk in token_chunks]\n",
        "\n",
        "    embeddings_response = get_embeddings(text_chunks, EMBEDDINGS_MODEL)\n",
        "    embeddings = [embedding[\"embedding\"] for embedding in embeddings_response]\n",
        "    text_embeddings = list(zip(text_chunks, embeddings))\n",
        "\n",
        "    average_embedding = get_col_average_from_list_of_lists(embeddings)\n",
        "\n",
        "    return (text_embeddings, average_embedding)\n",
        "\n",
        "def get_embeddings(text_array, engine):\n",
        "    return openai.Engine(id=engine).embeddings(input=text_array)[\"data\"]\n",
        "\n",
        "# Split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
        "def chunks(text, n, tokenizer):\n",
        "    \"\"\"Yield successive n-sized chunks from text.\"\"\"\n",
        "    tokens = tokenizer.encode(text)\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
        "        j = min(i + int(1.5 * n), len(tokens))\n",
        "        while j > i + int(0.5 * n):\n",
        "            # Decode the tokens and check for full stop or newline\n",
        "            chunk = tokenizer.decode(tokens[i:j])\n",
        "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
        "                break\n",
        "            j -= 1\n",
        "        # If no end of sentence found, use n tokens as the chunk size\n",
        "        if j == i + int(0.5 * n):\n",
        "            j = min(i + n, len(tokens))\n",
        "        yield tokens[i:j]\n",
        "        i = j\n",
        "\n",
        "def get_unique_id_for_file_chunk(filename, chunk_index):\n",
        "    return str(filename+\"-!\"+str(chunk_index))\n",
        "\n",
        "def handle_file_string(file, tokenizer, redis_conn, text_embedding_field, index_name):\n",
        "    \"\"\"\n",
        "    Handle a file string by cleaning it up, creating embeddings, and uploading them to Redis.\n",
        "\n",
        "    Args:\n",
        "        file (tuple): A tuple containing the filename and file body string.\n",
        "        tokenizer: The tokenizer object to use for encoding and decoding text.\n",
        "        redis_conn: The Redis connection object.\n",
        "        text_embedding_field (str): The field in Redis where the text embeddings will be stored.\n",
        "        index_name: The name of the index or identifier for the embeddings.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        Exception: If there is an error creating embeddings or uploading to Redis.\n",
        "\n",
        "    \"\"\"\n",
        "    filename = file[0]\n",
        "    file_body_string = file[1]\n",
        "\n",
        "    # Clean up the file string by replacing newlines, double spaces, and semi-colons\n",
        "    clean_file_body_string = file_body_string.replace(\"  \", \" \").replace(\"\\n\", \"; \").replace(';', ' ')\n",
        "\n",
        "    # Add the filename to the text to embed\n",
        "    text_to_embed = \"Filename is: {}; {}\".format(filename, clean_file_body_string)\n",
        "\n",
        "    try:\n",
        "        # Create embeddings for the text\n",
        "        text_embeddings, average_embedding = create_embeddings_for_text(text_to_embed, tokenizer)\n",
        "        # print(\"[handle_file_string] Created embedding for {}\".format(filename))\n",
        "    except Exception as e:\n",
        "        print(\"[handle_file_string] Error creating embedding: {}\".format(e))\n",
        "\n",
        "    # Get the vectors array of triples: file_chunk_id, embedding, metadata for each embedding\n",
        "    # Metadata is a dict with keys: filename, file_chunk_index\n",
        "    vectors = []\n",
        "    for i, (text_chunk, embedding) in enumerate(text_embeddings):\n",
        "        id = get_unique_id_for_file_chunk(filename, i)\n",
        "        vectors.append({'id': id, \"vector\": embedding, 'metadata': {\"filename\": filename,\n",
        "                                                                    \"text_chunk\": text_chunk,\n",
        "                                                                    \"file_chunk_index\": i}})\n",
        "\n",
        "    try:\n",
        "        # Load vectors into Redis\n",
        "        load_vectors(redis_conn, vectors, text_embedding_field)\n",
        "    except Exception as e:\n",
        "        print(f'Ran into a problem uploading to Redis: {e}')\n",
        "\n",
        "\n",
        "# Make a class to generate batches for insertion\n",
        "class BatchGenerator:\n",
        "\n",
        "\n",
        "    def __init__(self, batch_size: int = 10) -> None:\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    # Makes chunks out of an input DataFrame\n",
        "    def to_batches(self, df: pd.DataFrame) -> Iterator[pd.DataFrame]:\n",
        "        splits = self.splits_num(df.shape[0])\n",
        "        if splits <= 1:\n",
        "            yield df\n",
        "        else:\n",
        "            for chunk in np.array_split(df, splits):\n",
        "                yield chunk\n",
        "\n",
        "    # Determines how many chunks DataFrame contains\n",
        "    def splits_num(self, elements: int) -> int:\n",
        "        return round(elements / self.batch_size)\n",
        "\n",
        "    __call__ = to_batches"
      ],
      "metadata": {
        "id": "SEFKRKlKwM3c",
        "outputId": "809f63c7-bd88-4ebc-db02-841208d14f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SEFKRKlKwM3c",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing transformers2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ed23bf9d",
      "metadata": {
        "id": "ed23bf9d"
      },
      "outputs": [],
      "source": [
        "# The transformers.py file contains all of the transforming functions, including ones to chunk, embed and load data\n",
        "# For more details, check the file and work through each function individually\n",
        "from transformers2 import handle_file_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f299f6",
      "metadata": {
        "id": "31f299f6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# This step takes about 5 minutes\n",
        "\n",
        "# Initialise tokenizer\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# Process each PDF file and prepare for embedding\n",
        "for pdf_file in pdf_files:\n",
        "\n",
        "    pdf_path = os.path.join(data_dir,pdf_file)\n",
        "    print(pdf_path)\n",
        "\n",
        "    # Extract the raw text from each PDF using textract\n",
        "    text = textract.process(pdf_path, method='pdfminer')\n",
        "\n",
        "    # Chunk each document, embed the contents and load to Redis\n",
        "    handle_file_string((pdf_file,text.decode(\"utf-8\")),tokenizer,redis_client,VECTOR_FIELD_NAME,INDEX_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22aff597",
      "metadata": {
        "id": "22aff597",
        "outputId": "d12a25f1-3496-42bb-b988-4a9b47667d38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'829'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check that our docs have been inserted\n",
        "redis_client.ft(INDEX_NAME).info()['num_docs']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b12cb6e",
      "metadata": {
        "id": "6b12cb6e"
      },
      "source": [
        "## Make it a product\n",
        "\n",
        "Now we can test that our search works as intended by:\n",
        "- Querying our data in Redis using semantic search and verifying results\n",
        "- Adding a step to pass the results to GPT-3 for summarisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e921ac96",
      "metadata": {
        "id": "e921ac96"
      },
      "outputs": [],
      "source": [
        "from database import get_redis_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9dfacf",
      "metadata": {
        "id": "cb9dfacf",
        "outputId": "185df146-3831-4222-ab30-0e0ad2c1d766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 5.85 ms, sys: 2.61 ms, total: 8.45 ms\n",
            "Wall time: 240 ms\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>result</th>\n",
              "      <th>certainty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The IT will, therefore, be competent to establish the existence, or not, of a breach of the FIA   regulations and to impose any sanction upon the person and Competitor concerned (see the process   governed by the FIA Judicial and Disciplinary Rules).      The President of the FIA, in its capacity as prosecuting authority, will ask, in respect of every   disciplinary procedure:        -     -     for the imposition of a suspension upon Competitor’s Staff Certificate of Registration holders   who have contravened the FIA Code of Good Standing or the withdrawal of the Competitor’s   Staff Certificate of Registration (any withdrawal can only be imposed for the remaining period   of the current season of the FIA Formula One World Championship)  and      that these same people not be fined.        The person and/or Competitor sanctioned may bring an appeal before the ICA against the IT’s   decision.        *********        The FIA will inform the relevant Competitor of any proceedings instigated against any member of its   staff. It is the responsibility to the relevant Competitor to send the IT a written request to be heard, and   if granted, it shall be permitted to submit written observations. The FIA undertakes to support before   the IT and/or the ICA any request from the Competitor to intervene as a third party within the   framework of a disciplinary procedure.      The right to deprive any duly registered member of a Competitor’s staff of access to the Reserved   Areas at events forming part of the FIA Formula One World Championship is subject to the procedure   set forth in the FIA Judicial and Disciplinary Rules.      The Stewards during the course of an Event or otherwise will have no authority to suspend or   withdraw a Competitor’s Staff Certificate of Registration for any breach or alleged breach of the FIA   Code of Good Standing.</td>\n",
              "      <td>0.205749571323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The following sets out examples of the type of behaviours which might constitute an infringement of   the FIA Code of Good Standing (non-exhaustive list of examples) in relation to a person who is subject   to the Code of Good Standing:        -     -     -     -     giving instructions to a driver or other member of a Competitor’s staff with the intention or with   the likely result of causing an accident, collision or crash or a race to be stopped or   suspended    any action which is likely to endanger or materially compromise the safety of any driver, other   members of the Competitor’s staff, other participants in a race, Officials or any spectators or   other members of the public who attend an event    giving instructions to make any changes to a car in breach of any safety requirements or   regulations    giving instructions to tamper with or adversely affect the set-up or performance of the car of   any other Competitor      4 / 5                    \f",
              "FIA Legal Department   Practice Directions - Competitor’s Staff Registration System             17 March 2011     -     -     giving instructions to a driver or otherwise taking any action by which the result or course of a   race may be influenced or affected for the purpose of profiting or assisting someone to profit   through betting on the outcome of a race or any part of a race  or   being convicted of a criminal offence (other than a driving offence) which carries a maximum   prison sentence of five years.        VII.     AMENDMENTS TO THE COMPETITOR’S STAFF REGISTRATION SYSTEM        The FIA will not make any amendments with regard to the Competitor’s Staff Registration System,   either to the International Sporting Code or to the Practice Directions, prior consultation with the   Competitors entered in the FIA Formula One World Championship and adequate opportunity to   provide input on the proposed amendments.</td>\n",
              "      <td>0.206525266171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  \\\n",
              "0  0    \n",
              "1  1    \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     result  \\\n",
              "0        The IT will, therefore, be competent to establish the existence, or not, of a breach of the FIA   regulations and to impose any sanction upon the person and Competitor concerned (see the process   governed by the FIA Judicial and Disciplinary Rules).      The President of the FIA, in its capacity as prosecuting authority, will ask, in respect of every   disciplinary procedure:        -     -     for the imposition of a suspension upon Competitor’s Staff Certificate of Registration holders   who have contravened the FIA Code of Good Standing or the withdrawal of the Competitor’s   Staff Certificate of Registration (any withdrawal can only be imposed for the remaining period   of the current season of the FIA Formula One World Championship)  and      that these same people not be fined.        The person and/or Competitor sanctioned may bring an appeal before the ICA against the IT’s   decision.        *********        The FIA will inform the relevant Competitor of any proceedings instigated against any member of its   staff. It is the responsibility to the relevant Competitor to send the IT a written request to be heard, and   if granted, it shall be permitted to submit written observations. The FIA undertakes to support before   the IT and/or the ICA any request from the Competitor to intervene as a third party within the   framework of a disciplinary procedure.      The right to deprive any duly registered member of a Competitor’s staff of access to the Reserved   Areas at events forming part of the FIA Formula One World Championship is subject to the procedure   set forth in the FIA Judicial and Disciplinary Rules.      The Stewards during the course of an Event or otherwise will have no authority to suspend or   withdraw a Competitor’s Staff Certificate of Registration for any breach or alleged breach of the FIA   Code of Good Standing.                                      \n",
              "1        The following sets out examples of the type of behaviours which might constitute an infringement of   the FIA Code of Good Standing (non-exhaustive list of examples) in relation to a person who is subject   to the Code of Good Standing:        -     -     -     -     giving instructions to a driver or other member of a Competitor’s staff with the intention or with   the likely result of causing an accident, collision or crash or a race to be stopped or   suspended    any action which is likely to endanger or materially compromise the safety of any driver, other   members of the Competitor’s staff, other participants in a race, Officials or any spectators or   other members of the public who attend an event    giving instructions to make any changes to a car in breach of any safety requirements or   regulations    giving instructions to tamper with or adversely affect the set-up or performance of the car of   any other Competitor      4 / 5                    \n",
              "FIA Legal Department   Practice Directions - Competitor’s Staff Registration System             17 March 2011     -     -     giving instructions to a driver or otherwise taking any action by which the result or course of a   race may be influenced or affected for the purpose of profiting or assisting someone to profit   through betting on the outcome of a race or any part of a race  or   being convicted of a criminal offence (other than a driving offence) which carries a maximum   prison sentence of five years.        VII.     AMENDMENTS TO THE COMPETITOR’S STAFF REGISTRATION SYSTEM        The FIA will not make any amendments with regard to the Competitor’s Staff Registration System,   either to the International Sporting Code or to the Practice Directions, prior consultation with the   Competitors entered in the FIA Formula One World Championship and adequate opportunity to   provide input on the proposed amendments.   \n",
              "\n",
              "        certainty  \n",
              "0  0.205749571323  \n",
              "1  0.206525266171  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "f1_query='what are the criteria for disqualification'\n",
        "\n",
        "result_df = get_redis_results(redis_client,f1_query,index_name=INDEX_NAME)\n",
        "result_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51340903",
      "metadata": {
        "id": "51340903",
        "outputId": "8e9d1b61-a942-498e-9b59-c03d3285117d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Breach of FIA regulations can lead to disqualification\n",
            "- Imposed sanctions may include suspension of Competitor's Staff Certificate of Registration\n",
            "- Competitor's Staff Certificate of Registration may also be withdrawn for remaining duration of the season\n",
            "- Competitor has right to appeal the IT's decision\n",
            "- Competitor must make written request to be heard\n",
            "- FIA will support Competitor's request\n",
            "- Stewards have no authority to suspend or withdraw Competitor's Staff Certificate of Registration for any breach or alleged breach of the FIA Code of Good Standing\n"
          ]
        }
      ],
      "source": [
        "# Build a prompt to provide the original query, the result and ask to summarise for the user\n",
        "summary_prompt = '''Summarise this result in a bulleted list to answer the search query a customer has sent.\n",
        "Search query: SEARCH_QUERY_HERE\n",
        "Search result: SEARCH_RESULT_HERE\n",
        "Summary:\n",
        "'''\n",
        "summary_prepped = summary_prompt.replace('SEARCH_QUERY_HERE',f1_query).replace('SEARCH_RESULT_HERE',result_df['result'][0])\n",
        "summary = openai.Completion.create(engine=COMPLETIONS_MODEL,prompt=summary_prepped,max_tokens=500)\n",
        "# Response provided by GPT-3\n",
        "print(summary['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d008ff23",
      "metadata": {
        "id": "d008ff23"
      },
      "source": [
        "### Search\n",
        "\n",
        "Now that we've got our knowledge embedded and stored in Redis, we can now create an internal search application. Its not sophisticated but it'll get the job done for us.\n",
        "\n",
        "In the directory containing this app, execute ```streamlit run search.py```. This will open up a Streamlit app in your browser where you can ask questions of your embedded data.\n",
        "\n",
        "__Example Questions__:\n",
        "- what is the cost cap for a power unit in 2023\n",
        "- what should competitors include on their application form"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd12b31e",
      "metadata": {
        "id": "dd12b31e"
      },
      "source": [
        "## Build your moat\n",
        "\n",
        "The Q&A was useful, but fairly limited in the complexity of interaction we can have - if the user asks a sub-optimal question, there is no assistance from the system to prompt them for more info or conversation to lead them down the right path.\n",
        "\n",
        "For the next step we'll make a Chatbot using the Chat Completions endpoint, which will:\n",
        "- Be given instructions on how it should act and what the goals of its users are\n",
        "- Be supplied some required information that it needs to collect\n",
        "- Go back and forth with the customer until it has populated that information\n",
        "- Say a trigger word that will kick off semantic search and summarisation of the response\n",
        "\n",
        "For more details on our Chat Completions endpoint and how to interact with it, please check out the docs [here](https://platform.openai.com/docs/guides/chat)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34135886",
      "metadata": {
        "id": "34135886"
      },
      "source": [
        "### Framework\n",
        "\n",
        "This section outlines a basic framework for working with the API and storing context of previous conversation \"turns\". Once this is established, we'll extend it to use our retrieval endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45c0acc8",
      "metadata": {
        "id": "45c0acc8",
        "outputId": "b1602771-92b5-44a3-bf5e-2520322809df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: \n",
            "\n",
            "As an AI language model developed by OpenAI, I can help you in several ways. Here are some examples:\n",
            "\n",
            "\n",
            "- Answer questions: You can ask me any questions you have, and I'll do my best to provide accurate and helpful answers. I can help you with anything from math problems to historical facts to recommendations for restaurants or movies.\n",
            "\n",
            "- Assist in writing: Whether you need help with grammar, sentence structure, or word choice, I can assist you in writing. I can also help you generate ideas for writing assignments and provide writing prompts for inspiration.\n",
            "\n",
            "- Provide information: If you need information on a specific topic or want to learn more about a particular subject, I can provide you with useful information and resources.\n",
            "\n",
            "- Give suggestions: If you're unsure about something or need advice, I can give you suggestions and recommendations based on my knowledge and experience.\n",
            "\n",
            "- Chat and entertain: If you're feeling bored or lonely, I can chat with you and try to entertain you with jokes, stories, or interesting facts.\n"
          ]
        }
      ],
      "source": [
        "# A basic example of how to interact with our ChatCompletion endpoint\n",
        "# It requires a list of \"messages\", consisting of a \"role\" (one of system, user or assistant) and \"content\"\n",
        "question = 'How can you help me'\n",
        "\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": question}\n",
        "  ]\n",
        ")\n",
        "print(f\"{completion['choices'][0]['message']['role']}: {completion['choices'][0]['message']['content']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23e4fc55",
      "metadata": {
        "id": "23e4fc55"
      },
      "outputs": [],
      "source": [
        "from termcolor import colored\n",
        "\n",
        "# A basic class to create a message as a dict for chat\n",
        "class Message:\n",
        "\n",
        "\n",
        "    def __init__(self,role,content):\n",
        "\n",
        "        self.role = role\n",
        "        self.content = content\n",
        "\n",
        "    def message(self):\n",
        "\n",
        "        return {\"role\": self.role,\"content\": self.content}\n",
        "\n",
        "# Our assistant class we'll use to converse with the bot\n",
        "class Assistant:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def _get_assistant_response(self, prompt):\n",
        "\n",
        "        try:\n",
        "            completion = openai.ChatCompletion.create(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages=prompt\n",
        "            )\n",
        "\n",
        "            response_message = Message(completion['choices'][0]['message']['role'],completion['choices'][0]['message']['content'])\n",
        "            return response_message.message()\n",
        "\n",
        "        except Exception as e:\n",
        "\n",
        "            return f'Request failed with exception {e}'\n",
        "\n",
        "    def ask_assistant(self, next_user_prompt, colorize_assistant_replies=True):\n",
        "        [self.conversation_history.append(x) for x in next_user_prompt]\n",
        "        assistant_response = self._get_assistant_response(self.conversation_history)\n",
        "        self.conversation_history.append(assistant_response)\n",
        "        return assistant_response\n",
        "\n",
        "\n",
        "    def pretty_print_conversation_history(self, colorize_assistant_replies=True):\n",
        "        for entry in self.conversation_history:\n",
        "            if entry['role'] == 'system':\n",
        "                pass\n",
        "            else:\n",
        "                prefix = entry['role']\n",
        "                content = entry['content']\n",
        "                output = colored(prefix +':\\n' + content, 'green') if colorize_assistant_replies and entry['role'] == 'assistant' else prefix +':\\n' + content\n",
        "                print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e18c88b4",
      "metadata": {
        "id": "e18c88b4",
        "outputId": "c62f765d-5c77-4f4b-aad7-b616cfccaa1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are a helpful business assistant who has innovative ideas'},\n",
              " {'role': 'user', 'content': 'What can you do to help me'}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initiate our Assistant class\n",
        "conversation = Assistant()\n",
        "\n",
        "# Create a list to hold our messages and insert both a system message to guide behaviour and our first user question\n",
        "messages = []\n",
        "system_message = Message('system','You are a helpful business assistant who has innovative ideas')\n",
        "user_message = Message('user','What can you do to help me')\n",
        "messages.append(system_message.message())\n",
        "messages.append(user_message.message())\n",
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "377243c9",
      "metadata": {
        "id": "377243c9",
        "outputId": "a124e4a4-0933-451a-b533-60c635465025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As a business assistant with innovative ideas, I can:\n",
            "\n",
            "1. Conduct market research: I can carry out thorough research on your target market, analyze consumer behavior, and gather insights to help you make informed decisions about your business.\n",
            "\n",
            "2. Develop a strategic plan: I can help you come up with a comprehensive business plan that includes a clear vision, goals, and actionable steps to help you achieve your business objectives.\n",
            "\n",
            "3. Create a strong online presence: I can help you create a compelling website, develop a social media strategy, and create engaging online content to help you connect with your customers.\n",
            "\n",
            "4. Improve customer service: I can help you identify areas where your customer service needs improvement and help you develop strategies for how to provide excellent service to your customers.\n",
            "\n",
            "5. Optimize your operations: I can help you streamline your business processes, identify inefficiencies, and create systems that will improve productivity, reduce costs, and increase profitability.\n",
            "\n",
            "6. Explore new revenue streams: I can help you identify new opportunities for revenue generation, such as introducing new products or services, or expanding into new markets.\n",
            "\n",
            "7. Develop innovative marketing: I can help you come up with innovative marketing strategies that will help you stand out from competitors and resonate with your target audience.\n"
          ]
        }
      ],
      "source": [
        "# Get back a response from the Chatbot to our question\n",
        "response_message = conversation.ask_assistant(messages)\n",
        "print(response_message['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f364c3b5",
      "metadata": {
        "id": "f364c3b5",
        "outputId": "095ad069-03bf-4eb2-9fbc-a0e4d5dc0091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Developing a strategic plan is one of the most critical aspects of running a successful business. A strategic plan outlines a clear vision for your business and provides a roadmap for achieving your goals. As a business assistant, I can help you develop a comprehensive strategic plan that includes:\n",
            "\n",
            "1. A clear and concise vision statement that defines what you want to achieve with your business.\n",
            "\n",
            "2. An analysis of your competition and the market environment to identify opportunities and threats.\n",
            "\n",
            "3. A SWOT analysis to identify your business's strengths, weaknesses, opportunities, and threats.\n",
            "\n",
            "4. A clear set of objectives and goals that are specific, measurable, attainable, relevant, and time-bound.\n",
            "\n",
            "5. An action plan that outlines the steps you need to take to achieve your goals.\n",
            "\n",
            "6. A timeline that details when each objective will be completed.\n",
            "\n",
            "7. A monitoring and evaluation plan to keep track of your progress and identify areas that need improvement.\n",
            "\n",
            "By working together, we can develop a strategic plan that aligns with your long-term goals and helps you grow your business.\n"
          ]
        }
      ],
      "source": [
        "next_question = 'Tell me more about option 2'\n",
        "\n",
        "# Initiate a fresh messages list and insert our next question\n",
        "messages = []\n",
        "user_message = Message('user',next_question)\n",
        "messages.append(user_message.message())\n",
        "response_message = conversation.ask_assistant(messages)\n",
        "print(response_message['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62842a1",
      "metadata": {
        "id": "f62842a1",
        "outputId": "c741f2d4-b364-4619-a130-385bbd5658fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user:\n",
            "What can you do to help me\n",
            "\u001b[32massistant:\n",
            "As a business assistant with innovative ideas, I can:\n",
            "\n",
            "1. Conduct market research: I can carry out thorough research on your target market, analyze consumer behavior, and gather insights to help you make informed decisions about your business.\n",
            "\n",
            "2. Develop a strategic plan: I can help you come up with a comprehensive business plan that includes a clear vision, goals, and actionable steps to help you achieve your business objectives.\n",
            "\n",
            "3. Create a strong online presence: I can help you create a compelling website, develop a social media strategy, and create engaging online content to help you connect with your customers.\n",
            "\n",
            "4. Improve customer service: I can help you identify areas where your customer service needs improvement and help you develop strategies for how to provide excellent service to your customers.\n",
            "\n",
            "5. Optimize your operations: I can help you streamline your business processes, identify inefficiencies, and create systems that will improve productivity, reduce costs, and increase profitability.\n",
            "\n",
            "6. Explore new revenue streams: I can help you identify new opportunities for revenue generation, such as introducing new products or services, or expanding into new markets.\n",
            "\n",
            "7. Develop innovative marketing: I can help you come up with innovative marketing strategies that will help you stand out from competitors and resonate with your target audience.\u001b[0m\n",
            "user:\n",
            "Tell me more about option 2\n",
            "\u001b[32massistant:\n",
            "Developing a strategic plan is one of the most critical aspects of running a successful business. A strategic plan outlines a clear vision for your business and provides a roadmap for achieving your goals. As a business assistant, I can help you develop a comprehensive strategic plan that includes:\n",
            "\n",
            "1. A clear and concise vision statement that defines what you want to achieve with your business.\n",
            "\n",
            "2. An analysis of your competition and the market environment to identify opportunities and threats.\n",
            "\n",
            "3. A SWOT analysis to identify your business's strengths, weaknesses, opportunities, and threats.\n",
            "\n",
            "4. A clear set of objectives and goals that are specific, measurable, attainable, relevant, and time-bound.\n",
            "\n",
            "5. An action plan that outlines the steps you need to take to achieve your goals.\n",
            "\n",
            "6. A timeline that details when each objective will be completed.\n",
            "\n",
            "7. A monitoring and evaluation plan to keep track of your progress and identify areas that need improvement.\n",
            "\n",
            "By working together, we can develop a strategic plan that aligns with your long-term goals and helps you grow your business.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Print out a log of our conversation so far\n",
        "\n",
        "conversation.pretty_print_conversation_history()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f18d5b54",
      "metadata": {
        "id": "f18d5b54"
      },
      "source": [
        "### Knowledge retrieval\n",
        "\n",
        "Now we'll extend the class to call a downstream service when a stop sequence is spoken by the Chatbot.\n",
        "\n",
        "The main changes are:\n",
        "- The system message is more comprehensive, giving criteria for the Chatbot to advance the conversation\n",
        "- Adding an explicit stop sequence for it to use when it has the info it needs\n",
        "- Extending the class with a function ```_get_search_results``` which sources Redis results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0cef87",
      "metadata": {
        "id": "8a0cef87"
      },
      "outputs": [],
      "source": [
        "# Updated system prompt requiring Question and Year to be extracted from the user\n",
        "system_prompt = '''\n",
        "You are a helpful Formula 1 knowledge base assistant. You need to capture a Question and Year from each customer.\n",
        "The Question is their query on Formula 1, and the Year is the year of the applicable Formula 1 season.\n",
        "If they haven't provided the Year, ask them for it again.\n",
        "Once you have the Year, say \"searching for answers\".\n",
        "\n",
        "Example 1:\n",
        "\n",
        "User: I'd like to know the cost cap for a power unit\n",
        "\n",
        "Assistant: Certainly, what year would you like this for?\n",
        "\n",
        "User: 2023 please.\n",
        "\n",
        "Assistant: Searching for answers.\n",
        "'''\n",
        "\n",
        "# New Assistant class to add a vector database call to its responses\n",
        "class RetrievalAssistant:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def _get_assistant_response(self, prompt):\n",
        "\n",
        "        try:\n",
        "            completion = openai.ChatCompletion.create(\n",
        "              model=CHAT_MODEL,\n",
        "              messages=prompt,\n",
        "              temperature=0.1\n",
        "            )\n",
        "\n",
        "            response_message = Message(completion['choices'][0]['message']['role'],completion['choices'][0]['message']['content'])\n",
        "            return response_message.message()\n",
        "\n",
        "        except Exception as e:\n",
        "\n",
        "            return f'Request failed with exception {e}'\n",
        "\n",
        "    # The function to retrieve Redis search results\n",
        "    def _get_search_results(self,prompt):\n",
        "        latest_question = prompt\n",
        "        search_content = get_redis_results(redis_client,latest_question,INDEX_NAME)['result'][0]\n",
        "        return search_content\n",
        "\n",
        "\n",
        "    def ask_assistant(self, next_user_prompt):\n",
        "        [self.conversation_history.append(x) for x in next_user_prompt]\n",
        "        assistant_response = self._get_assistant_response(self.conversation_history)\n",
        "\n",
        "        # Answer normally unless the trigger sequence is used \"searching_for_answers\"\n",
        "        if 'searching for answers' in assistant_response['content'].lower():\n",
        "            question_extract = openai.Completion.create(model=COMPLETIONS_MODEL,prompt=f\"Extract the user's latest question and the year for that question from this conversation: {self.conversation_history}. Extract it as a sentence stating the Question and Year\")\n",
        "            search_result = self._get_search_results(question_extract['choices'][0]['text'])\n",
        "\n",
        "            # We insert an extra system prompt here to give fresh context to the Chatbot on how to use the Redis results\n",
        "            # In this instance we add it to the conversation history, but in production it may be better to hide\n",
        "            self.conversation_history.insert(-1,{\"role\": 'system',\"content\": f\"Answer the user's question using this content: {search_result}. If you cannot answer the question, say 'Sorry, I don't know the answer to this one'\"})\n",
        "            #[self.conversation_history.append(x) for x in next_user_prompt]\n",
        "\n",
        "            assistant_response = self._get_assistant_response(self.conversation_history)\n",
        "            print(next_user_prompt)\n",
        "            print(assistant_response)\n",
        "            self.conversation_history.append(assistant_response)\n",
        "            return assistant_response\n",
        "        else:\n",
        "            self.conversation_history.append(assistant_response)\n",
        "            return assistant_response\n",
        "\n",
        "\n",
        "    def pretty_print_conversation_history(self, colorize_assistant_replies=True):\n",
        "        for entry in self.conversation_history:\n",
        "            if entry['role'] == 'system':\n",
        "                pass\n",
        "            else:\n",
        "                prefix = entry['role']\n",
        "                content = entry['content']\n",
        "                output = colored(prefix +':\\n' + content, 'green') if colorize_assistant_replies and entry['role'] == 'assistant' else prefix +':\\n' + content\n",
        "                #prefix = entry['role']\n",
        "                print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "101d502c",
      "metadata": {
        "id": "101d502c",
        "outputId": "99a4342c-19e7-4af2-d403-bd889d27cfe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'assistant',\n",
              " 'content': 'Sure, what year would you like this information for?'}"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation = RetrievalAssistant()\n",
        "messages = []\n",
        "system_message = Message('system',system_prompt)\n",
        "user_message = Message('user','How can a competitor be disqualified from competition')\n",
        "messages.append(system_message.message())\n",
        "messages.append(user_message.message())\n",
        "response_message = conversation.ask_assistant(messages)\n",
        "response_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "702eb4fc",
      "metadata": {
        "id": "702eb4fc",
        "outputId": "b5b0c645-6282-4022-a7be-5d57c0ed3184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'user', 'content': 'For 2023 please.'}]\n",
            "{'role': 'assistant', 'content': 'According to the FIA Sporting Regulations for the 2023 Formula One season, a competitor can be disqualified from the competition if they breach the FIA regulations. The FIA will investigate and establish the existence of the breach and impose any sanction upon the person and competitor concerned. The President of the FIA, in its capacity as prosecuting authority, will ask for the imposition of a suspension upon Competitor’s Staff Certificate of Registration holders who have contravened the FIA Code of Good Standing or the withdrawal of the Competitor’s Staff Certificate of Registration. The person and/or competitor sanctioned may bring an appeal before the ICA against the IT’s decision.'}\n"
          ]
        }
      ],
      "source": [
        "messages = []\n",
        "user_message = Message('user','For 2023 please.')\n",
        "messages.append(user_message.message())\n",
        "response_message = conversation.ask_assistant(messages)\n",
        "#response_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f2c812",
      "metadata": {
        "id": "e2f2c812",
        "outputId": "18117497-3b42-41be-f457-ddbc67e8ce30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user:\n",
            "How can a competitor be disqualified from competition\n",
            "\u001b[32massistant:\n",
            "Sure, what year would you like this information for?\u001b[0m\n",
            "user:\n",
            "For 2023 please.\n",
            "\u001b[32massistant:\n",
            "According to the FIA Sporting Regulations for the 2023 Formula One season, a competitor can be disqualified from the competition if they breach the FIA regulations. The FIA will investigate and establish the existence of the breach and impose any sanction upon the person and competitor concerned. The President of the FIA, in its capacity as prosecuting authority, will ask for the imposition of a suspension upon Competitor’s Staff Certificate of Registration holders who have contravened the FIA Code of Good Standing or the withdrawal of the Competitor’s Staff Certificate of Registration. The person and/or competitor sanctioned may bring an appeal before the ICA against the IT’s decision.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "conversation.pretty_print_conversation_history()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9f9ef37",
      "metadata": {
        "id": "a9f9ef37"
      },
      "source": [
        "### Chatbot\n",
        "\n",
        "Now we'll put all this into action with a real (basic) Chatbot.\n",
        "\n",
        "In the directory containing this app, execute ```streamlit run chat.py```. This will open up a Streamlit app in your browser where you can ask questions of your embedded data.\n",
        "\n",
        "__Example Questions__:\n",
        "- what is the cost cap for a power unit in 2023\n",
        "- what should competitors include on their application form\n",
        "- how can a competitor be disqualified"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8e6c4ca",
      "metadata": {
        "id": "b8e6c4ca"
      },
      "source": [
        "### Consolidation\n",
        "\n",
        "Over the course of this notebook you have:\n",
        "- Laid the foundations of your product by embedding our knowledge base\n",
        "- Created a Q&A application to serve basic use cases\n",
        "- Extended this to be an interactive Chatbot\n",
        "\n",
        "These are the foundational building blocks of any Q&A or Chat application using our APIs - these are your starting point, and we look forward to seeing what you build with them!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "oaibook",
      "language": "python",
      "name": "oaibook"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}